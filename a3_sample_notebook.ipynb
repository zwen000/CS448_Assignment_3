{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/zwen000/CS448_Assignment_3/blob/main/a3_sample_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\\(\\^Be sure to update this button to point to your notebook instead of the sample notebook\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge,LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score,ShuffleSplit,cross_val_predict\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature °C</th>\n",
       "      <th>Mols KCL</th>\n",
       "      <th>Size nm^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>647</td>\n",
       "      <td>6.244743e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>403</td>\n",
       "      <td>694</td>\n",
       "      <td>5.779610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>975</td>\n",
       "      <td>6.196847e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779</td>\n",
       "      <td>916</td>\n",
       "      <td>1.460449e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901</td>\n",
       "      <td>18</td>\n",
       "      <td>4.325726e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>545</td>\n",
       "      <td>637</td>\n",
       "      <td>7.124634e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>660</td>\n",
       "      <td>519</td>\n",
       "      <td>7.006960e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143</td>\n",
       "      <td>869</td>\n",
       "      <td>2.718260e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>461</td>\n",
       "      <td>8.919803e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>294</td>\n",
       "      <td>776</td>\n",
       "      <td>4.770210e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>991</td>\n",
       "      <td>117</td>\n",
       "      <td>2.441771e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>307</td>\n",
       "      <td>781</td>\n",
       "      <td>5.006455e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>206</td>\n",
       "      <td>70</td>\n",
       "      <td>3.145200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>437</td>\n",
       "      <td>599</td>\n",
       "      <td>5.390215e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>566</td>\n",
       "      <td>75</td>\n",
       "      <td>9.185271e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temperature °C  Mols KCL     Size nm^3\n",
       "0              469       647  6.244743e+05\n",
       "1              403       694  5.779610e+05\n",
       "2              302       975  6.196847e+05\n",
       "3              779       916  1.460449e+06\n",
       "4              901        18  4.325726e+04\n",
       "5              545       637  7.124634e+05\n",
       "6              660       519  7.006960e+05\n",
       "7              143       869  2.718260e+05\n",
       "8               89       461  8.919803e+04\n",
       "9              294       776  4.770210e+05\n",
       "10             991       117  2.441771e+05\n",
       "11             307       781  5.006455e+05\n",
       "12             206        70  3.145200e+04\n",
       "13             437       599  5.390215e+05\n",
       "14             566        75  9.185271e+04"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pandas load the dataset (load remotely, not locally)\n",
    "# Output the first 15 rows of the data\n",
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\")\n",
    "df.head(15)\n",
    "# df.loc[i][[\"Temperature °C\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      "Temperature °C    1000 non-null int64\n",
      "Mols KCL          1000 non-null int64\n",
      "Size nm^3         1000 non-null float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 23.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Temperature °C  Mols KCL\n",
       " 0               469       647\n",
       " 1               403       694\n",
       " 2               302       975\n",
       " 3               779       916\n",
       " 4               901        18\n",
       " 5               545       637\n",
       " 6               660       519\n",
       " 7               143       869\n",
       " 8                89       461\n",
       " 9               294       776\n",
       " 10              991       117\n",
       " 11              307       781\n",
       " 12              206        70\n",
       " 13              437       599\n",
       " 14              566        75\n",
       " 15               62       293\n",
       " 16              331       781\n",
       " 17               35       149\n",
       " 18              905        76\n",
       " 19              227       864\n",
       " 20              913        66\n",
       " 21              709       332\n",
       " 22              626       903\n",
       " 23               38       163\n",
       " 24              849       243\n",
       " 25              899         5\n",
       " 26              539       725\n",
       " 27              230       665\n",
       " 28              396       846\n",
       " 29              132       777\n",
       " ..              ...       ...\n",
       " 870             393       388\n",
       " 871              14        43\n",
       " 872             254       662\n",
       " 873             826       386\n",
       " 874             526        25\n",
       " 875             411       661\n",
       " 876             435       929\n",
       " 877             572       263\n",
       " 878             193       316\n",
       " 879             974       803\n",
       " 880             900       281\n",
       " 881             339       426\n",
       " 882             573       423\n",
       " 883             390       511\n",
       " 884             142       549\n",
       " 885             647       711\n",
       " 886             915       545\n",
       " 887             571       388\n",
       " 888             482       564\n",
       " 889             428       677\n",
       " 890             400       160\n",
       " 891             906       363\n",
       " 892             564        86\n",
       " 893             271       937\n",
       " 894              40       173\n",
       " 895             465       485\n",
       " 896             161       622\n",
       " 897             923       871\n",
       " 898             702       111\n",
       " 899             296       884\n",
       " \n",
       " [900 rows x 2 columns],      Temperature °C  Mols KCL\n",
       " 900             686       339\n",
       " 901             577       469\n",
       " 902             752       701\n",
       " 903             402       978\n",
       " 904             107       140\n",
       " 905             857       383\n",
       " 906             310       793\n",
       " 907             943       269\n",
       " 908             120       145\n",
       " 909             187       575\n",
       " 910             374       864\n",
       " 911             816       126\n",
       " 912             668       393\n",
       " 913             848       237\n",
       " 914             419       873\n",
       " 915              97       509\n",
       " 916             806       872\n",
       " 917             253       676\n",
       " 918             878       894\n",
       " 919             351       478\n",
       " 920             964       541\n",
       " 921             514        81\n",
       " 922             496       605\n",
       " 923             381       493\n",
       " 924             387       602\n",
       " 925             633        71\n",
       " 926             544        70\n",
       " 927             376       609\n",
       " 928             855       547\n",
       " 929             615       525\n",
       " ..              ...       ...\n",
       " 970             837       160\n",
       " 971             286       535\n",
       " 972             325       681\n",
       " 973             225       275\n",
       " 974             730        72\n",
       " 975             757       680\n",
       " 976             771       401\n",
       " 977             212       542\n",
       " 978             741       632\n",
       " 979             693       422\n",
       " 980             164       475\n",
       " 981             859       811\n",
       " 982             347       274\n",
       " 983             782       463\n",
       " 984             748       836\n",
       " 985              16        53\n",
       " 986             853       458\n",
       " 987             276       720\n",
       " 988             250        83\n",
       " 989             119       510\n",
       " 990             841        48\n",
       " 991             998       655\n",
       " 992             436       543\n",
       " 993             311       265\n",
       " 994              21        73\n",
       " 995             894       847\n",
       " 996             327       982\n",
       " 997             791       213\n",
       " 998             769       553\n",
       " 999             919       452\n",
       " \n",
       " [100 rows x 2 columns],         Size nm^3\n",
       " 0    6.244743e+05\n",
       " 1    5.779610e+05\n",
       " 2    6.196847e+05\n",
       " 3    1.460449e+06\n",
       " 4    4.325726e+04\n",
       " 5    7.124634e+05\n",
       " 6    7.006960e+05\n",
       " 7    2.718260e+05\n",
       " 8    8.919803e+04\n",
       " 9    4.770210e+05\n",
       " 10   2.441771e+05\n",
       " 11   5.006455e+05\n",
       " 12   3.145200e+04\n",
       " 13   5.390215e+05\n",
       " 14   9.185271e+04\n",
       " 15   3.952883e+04\n",
       " 16   5.384215e+05\n",
       " 17   1.148431e+04\n",
       " 18   1.485850e+05\n",
       " 19   4.163085e+05\n",
       " 20   1.315965e+05\n",
       " 21   4.824333e+05\n",
       " 22   1.161365e+06\n",
       " 23   1.360311e+04\n",
       " 24   4.244891e+05\n",
       " 25   1.977871e+04\n",
       " 26   8.030359e+05\n",
       " 27   3.212950e+05\n",
       " 28   6.952330e+05\n",
       " 29   2.239614e+05\n",
       " ..            ...\n",
       " 870  3.139853e+05\n",
       " 871  1.424829e+03\n",
       " 872  3.518653e+05\n",
       " 873  6.518410e+05\n",
       " 874  3.262986e+04\n",
       " 875  5.607575e+05\n",
       " 876  8.381083e+05\n",
       " 877  3.097123e+05\n",
       " 878  1.271450e+05\n",
       " 879  1.594355e+06\n",
       " 880  5.188560e+05\n",
       " 881  2.980810e+05\n",
       " 882  4.967463e+05\n",
       " 883  4.107206e+05\n",
       " 884  1.662315e+05\n",
       " 885  9.422415e+05\n",
       " 886  1.016816e+06\n",
       " 887  4.542493e+05\n",
       " 888  5.585685e+05\n",
       " 889  5.977431e+05\n",
       " 890  1.335314e+05\n",
       " 891  6.723928e+05\n",
       " 892  1.039873e+05\n",
       " 893  5.361908e+05\n",
       " 894  1.517511e+04\n",
       " 895  4.633507e+05\n",
       " 896  2.132698e+05\n",
       " 897  1.640617e+06\n",
       " 898  1.646200e+05\n",
       " 899  5.492073e+05\n",
       " \n",
       " [900 rows x 1 columns],         Size nm^3\n",
       " 900  4.766235e+05\n",
       " 901  5.544346e+05\n",
       " 902  1.077368e+06\n",
       " 903  8.184641e+05\n",
       " 904  3.180400e+04\n",
       " 905  6.709371e+05\n",
       " 906  5.133471e+05\n",
       " 907  5.207175e+05\n",
       " 908  3.684071e+04\n",
       " 909  2.267404e+05\n",
       " 910  6.720885e+05\n",
       " 911  2.158776e+05\n",
       " 912  5.374768e+05\n",
       " 913  4.137328e+05\n",
       " 914  7.583771e+05\n",
       " 915  1.073123e+05\n",
       " 916  1.437061e+06\n",
       " 917  3.581485e+05\n",
       " 918  1.603235e+06\n",
       " 919  3.462961e+05\n",
       " 920  1.062978e+06\n",
       " 921  8.962346e+04\n",
       " 922  6.165699e+05\n",
       " 923  3.871823e+05\n",
       " 924  4.809464e+05\n",
       " 925  9.762603e+04\n",
       " 926  8.282800e+04\n",
       " 927  4.730766e+05\n",
       " 928  9.541788e+05\n",
       " 929  6.610050e+05\n",
       " ..            ...\n",
       " 970  2.786154e+05\n",
       " 971  3.176299e+05\n",
       " 972  4.598003e+05\n",
       " 973  1.286107e+05\n",
       " 974  1.140281e+05\n",
       " 975  1.051815e+06\n",
       " 976  6.321883e+05\n",
       " 977  2.407453e+05\n",
       " 978  9.569281e+05\n",
       " 979  5.982961e+05\n",
       " 980  1.642144e+05\n",
       " 981  1.422398e+06\n",
       " 982  1.964650e+05\n",
       " 983  7.396408e+05\n",
       " 984  1.279600e+06\n",
       " 985  1.968257e+03\n",
       " 986  7.975773e+05\n",
       " 987  4.155634e+05\n",
       " 988  4.469683e+04\n",
       " 989  1.302394e+05\n",
       " 990  9.089383e+04\n",
       " 991  1.331614e+06\n",
       " 992  4.871523e+05\n",
       " 993  1.705684e+05\n",
       " 994  3.470257e+03\n",
       " 995  1.545661e+06\n",
       " 996  6.737041e+05\n",
       " 997  3.477543e+05\n",
       " 998  8.684794e+05\n",
       " 999  8.476413e+05\n",
       " \n",
       " [100 rows x 1 columns])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the pandas dataset and split it into our features (X) and label (y)\n",
    "features = df[[\"Temperature °C\", \"Mols KCL\"]]\n",
    "label = df[[\"Size nm^3\"]]\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.1, shuffle=False)\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Perform a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample datapoint X: [[123, 456]], Prediction of  y:  [[159600.27372536]]\n",
      "Score of the model:  0.8868651637773253\n",
      "Intercept:  [-416783.91800716]\n",
      "Coefficents [[ 879.90717015 1026.65703904]]\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to train a model on the training set\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Create a sample datapoint and predict the output of that sample with the trained model\n",
    "sample_point = np.array([[123, 456]])\n",
    "y_prediction = model.predict(sample_point)\n",
    "print(\"Sample datapoint X: [[123, 456]], Prediction of  y: \", y_prediction )\n",
    "\n",
    "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Score of the model: \", score)\n",
    "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
    "intercept = model.intercept_\n",
    "coef = model.coef_\n",
    "\n",
    "print (\"Intercept: \", intercept)\n",
    "print (\"Coefficents\", coef)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "Score = 0.8868651637773253\n",
    "\n",
    "The score is the coefficient of prediction, it represents the model's capability in predicting the correct label. The best possible score is 1.0, a model with a score closer to 1.0 predicts result closer to the correct label.\n",
    "Our model has score 0.8868651637773253, very close to 1.0, that is suggesting that our model is fitted pretty well to the existing data, our predicted results will show relatively high accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Equation\n",
    "$\n",
    "h(x) = \\theta_0 + \\theta_1 * x_1 + \\theta_2 * x_2\\\\\n",
    "h(x) = -416783.91800716 + 879.90717015 * x_1 + 1026.65703904 * x_2\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample equation: $E = mc^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Use Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87616468 0.86951566 0.83708494 0.86963943 0.84945355 0.86236913\n",
      " 0.82467112 0.85236386 0.8648058  0.76555589]\n",
      "0.8471624047034034 0.03112537713964668\n"
     ]
    }
   ],
   "source": [
    "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
    "my_cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "scores = cross_val_score(model, features, label, cv=my_cv)\n",
    "\n",
    "print(scores)\n",
    "print(scores.mean(), scores.std())\n",
    "# Report on their finding and their significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function divided the original dataset and repeat experiment model fitting on the dataset 10 times, with different ways of shuffling each time. Finally, it returned scores for each experiment.\n",
    "\n",
    " The scores are rather close to the score of our model from part 3,this shows that our model is fitted well, even shuffling the dataset in different way doesn't improve the performance for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Using Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "              fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "              normalize=False, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.fit_transform(X_test)\n",
    "\n",
    "model = BayesianRidge()\n",
    "model.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  1.0\n",
      "Intercept:  2.133921952918172e-05\n",
      "Coefficents [ 0.00000000e+00  1.20000000e+01 -1.35692972e-07  1.01003650e-11\n",
      "  2.00000000e+00  2.85714287e-02]\n"
     ]
    }
   ],
   "source": [
    "print(\"Score: \", model.score(X_test, y_test))\n",
    "intercept = model.intercept_\n",
    "coef = model.coef_\n",
    "\n",
    "print (\"Intercept: \", intercept)\n",
    "print (\"Coefficents\", coef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.76623457e+05, 5.54434600e+05, 1.07736803e+06, 8.18464114e+05,\n",
       "       3.18040000e+04, 6.70937114e+05, 5.13347114e+05, 5.20717457e+05,\n",
       "       3.68407143e+04, 2.26740429e+05, 6.72088457e+05, 2.15877600e+05,\n",
       "       5.37476829e+05, 4.13732829e+05, 7.58377114e+05, 1.07312314e+05,\n",
       "       1.43706126e+06, 3.58148457e+05, 1.60323531e+06, 3.46296114e+05,\n",
       "       1.06297831e+06, 8.96234571e+04, 6.16569857e+05, 3.87182257e+05,\n",
       "       4.80946400e+05, 9.76260286e+04, 8.28280000e+04, 4.73076600e+05,\n",
       "       9.54178829e+05, 6.61005000e+05, 1.14400011e+06, 6.12330286e+04,\n",
       "       9.29079314e+05, 1.03529243e+06, 5.02000000e+04, 1.70761660e+06,\n",
       "       2.16700286e+04, 7.74480114e+05, 3.55214714e+05, 7.38879429e+05,\n",
       "       2.51469829e+05, 2.53718829e+05, 5.21228571e+04, 2.30945716e+03,\n",
       "       4.22685029e+05, 2.00866257e+05, 3.47416457e+05, 1.50313257e+05,\n",
       "       1.72224626e+06, 1.65311430e+03, 4.81235314e+05, 1.37193257e+05,\n",
       "       4.26357257e+05, 1.32183143e+06, 6.74216000e+04, 7.26984429e+05,\n",
       "       8.26151143e+04, 1.04350560e+06, 1.48401400e+05, 4.32204572e+04,\n",
       "       3.31453714e+05, 4.73130286e+04, 1.77567400e+05, 1.16260029e+05,\n",
       "       1.24290600e+05, 2.35764114e+05, 1.21469714e+05, 1.05945026e+06,\n",
       "       2.63337829e+05, 9.81716600e+05, 2.78615429e+05, 3.17629857e+05,\n",
       "       4.59800314e+05, 1.28610714e+05, 1.14028114e+05, 1.05181543e+06,\n",
       "       6.32188314e+05, 2.40745257e+05, 9.56928114e+05, 5.98296114e+05,\n",
       "       1.64214429e+05, 1.42239803e+06, 1.96465029e+05, 7.39640829e+05,\n",
       "       1.27960046e+06, 1.96825716e+03, 7.97577257e+05, 4.15563429e+05,\n",
       "       4.46968286e+04, 1.30239429e+05, 9.08938286e+04, 1.33161386e+06,\n",
       "       4.87152257e+05, 1.70568429e+05, 3.47025715e+03, 1.54566140e+06,\n",
       "       6.73704114e+05, 3.47754257e+05, 8.68479400e+05, 8.47641257e+05])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y = model.predict(X_test)\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Size nm^3\n",
      "900  4.766235e+05\n",
      "901  5.544346e+05\n",
      "902  1.077368e+06\n",
      "903  8.184641e+05\n",
      "904  3.180400e+04\n",
      "905  6.709371e+05\n",
      "906  5.133471e+05\n",
      "907  5.207175e+05\n",
      "908  3.684071e+04\n",
      "909  2.267404e+05\n",
      "910  6.720885e+05\n",
      "911  2.158776e+05\n",
      "912  5.374768e+05\n",
      "913  4.137328e+05\n",
      "914  7.583771e+05\n",
      "915  1.073123e+05\n",
      "916  1.437061e+06\n",
      "917  3.581485e+05\n",
      "918  1.603235e+06\n",
      "919  3.462961e+05\n",
      "920  1.062978e+06\n",
      "921  8.962346e+04\n",
      "922  6.165699e+05\n",
      "923  3.871823e+05\n",
      "924  4.809464e+05\n",
      "925  9.762603e+04\n",
      "926  8.282800e+04\n",
      "927  4.730766e+05\n",
      "928  9.541788e+05\n",
      "929  6.610050e+05\n",
      "..            ...\n",
      "970  2.786154e+05\n",
      "971  3.176299e+05\n",
      "972  4.598003e+05\n",
      "973  1.286107e+05\n",
      "974  1.140281e+05\n",
      "975  1.051815e+06\n",
      "976  6.321883e+05\n",
      "977  2.407453e+05\n",
      "978  9.569281e+05\n",
      "979  5.982961e+05\n",
      "980  1.642144e+05\n",
      "981  1.422398e+06\n",
      "982  1.964650e+05\n",
      "983  7.396408e+05\n",
      "984  1.279600e+06\n",
      "985  1.968257e+03\n",
      "986  7.975773e+05\n",
      "987  4.155634e+05\n",
      "988  4.469683e+04\n",
      "989  1.302394e+05\n",
      "990  9.089383e+04\n",
      "991  1.331614e+06\n",
      "992  4.871523e+05\n",
      "993  1.705684e+05\n",
      "994  3.470257e+03\n",
      "995  1.545661e+06\n",
      "996  6.737041e+05\n",
      "997  3.477543e+05\n",
      "998  8.684794e+05\n",
      "999  8.476413e+05\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report on the metrics and output the resultant equation as you did in Part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Equation\n",
    "$\n",
    "h(x) = 2.133921952918172\\mathrm{e}{-05} + 0.00000000 + 1.20000000\\mathrm{e}{+01} * a - 1.35692972\\mathrm{e}{-07} * b + 1.01003650\\mathrm{e}{-11} * a^2 + 2.00000000 * ab + 2.85714287\\mathrm{e}{-02} * b^2\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "I used BayesianRidge()in part 5,the model's score is 1.0,the highest possible score for a model, the model can predict the correct result for sure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
